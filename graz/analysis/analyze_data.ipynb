{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from matplotlib  import pyplot as plt\n",
    "import pyntbci\n",
    "import os\n",
    "import yaml\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining relevant functions\n",
    "def accuracy_across_folds(X: np.ndarray, y: np.ndarray, codes: np.ndarray, fs: int, transient_size:float, trial_time:int, n_folds:int=4, plot:bool = False):\n",
    "    \"\"\"\n",
    "    Computes classification accuracy for n = n_folds\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): EEG data (trials x channels x samples)\n",
    "        y (np.ndarray): labels of trials\n",
    "        codes (np.ndarray): codes used in the experiment\n",
    "        fs (int): downsampling frequency\n",
    "        transient_size (float): duration of the transient response in seconds\n",
    "        trial_time (int): duration for which codes were flashing on the screen\n",
    "        n_folds (int, optional): number of folds for cross-validation. Defaults to 4.\n",
    "        plot (bool, optional): plot the accuracy per fold. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.array: row vector containing accuracies of n_folds\n",
    "    \"\"\"\n",
    " \n",
    "    n_samples = int(trial_time * fs)\n",
    "    n_trials = X.shape[0]\n",
    "    n_classes = codes.shape[0]\n",
    "    \n",
    "    # Chronological cross-validation\n",
    "    folds = np.repeat(np.arange(n_folds), int(n_trials / n_folds))\n",
    "    \n",
    "    # Loop folds over different transient sizes\n",
    "    accuracy = np.zeros(n_folds)\n",
    "\n",
    "    for i_fold in range(n_folds):\n",
    "        \n",
    "        # Split data to train and test set\n",
    "        X_trn, y_trn = X[folds != i_fold, :, :n_samples], y[folds != i_fold]\n",
    "        X_tst, y_tst = X[folds == i_fold, :, :n_samples], y[folds == i_fold]\n",
    "\n",
    "        # Train template-matching classifier\n",
    "        rcca = pyntbci.classifiers.rCCA(codes= codes, fs = fs, event = \"duration\", transient_size = transient_size, onset_event = True)\n",
    "        rcca.fit(X_trn, y_trn)\n",
    "\n",
    "        # Apply template-matching classifier\n",
    "        yh_tst = rcca.predict(X_tst)\n",
    "\n",
    "        # Compute accuracy\n",
    "        accuracy[i_fold] = np.mean(yh_tst == y_tst)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        plt.bar(np.arange(n_folds), accuracy)\n",
    "        plt.axhline(accuracy.mean(), linestyle='--', alpha=0.5, label=\"average\")\n",
    "        plt.axhline(1 / n_classes, color=\"k\", linestyle=\"--\", alpha=0.5, label=\"chance\")\n",
    "        plt.xlabel(\"(test) fold\")\n",
    "        plt.ylabel(\"accuracy\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Chronological cross-validation\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = r'C:\\Users\\s1081686\\Desktop\\RA_Project\\graz_conference'\n",
    "\n",
    "# load relevant parameters\n",
    "with open(os.path.join(project_path,'config.yml'), \"r\") as yaml_file:\n",
    "    config_data = yaml.safe_load(yaml_file)\n",
    "    \n",
    "analysis_params = config_data['analysis_params']\n",
    "experimental_params = config_data['experimental_params']\n",
    "\n",
    "n_trials = experimental_params['N_TRIALS']\n",
    "trial_time = experimental_params['TRIAL_TIME']\n",
    "\n",
    "n_channels = analysis_params['N_CHANNELS']\n",
    "fs = analysis_params['Fs'] # downsampled frequency\n",
    "n_subjects = analysis_params['N_SUBJECTS']\n",
    "n_runs_ov = analysis_params['N_RUNS_OVERT'] # number of runs in the overt condition\n",
    "n_runs_cov = analysis_params['N_RUNS_COVERT']\n",
    "\n",
    "# loading paths\n",
    "data_path = analysis_params['DATA_PATH']\n",
    "\n",
    "# preprocessed eeg data filenames of all subjects\n",
    "subjects_overt = analysis_params['subjects_overt']\n",
    "subjects_covert = analysis_params['subjects_covert']\n",
    "\n",
    "# path to store results\n",
    "results_path = os.path.join(project_path,'analysis','result_variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data for subject 1\n",
      "loading data for subject 2\n",
      "loading data for subject 3\n",
      "loading data for subject 4\n",
      "loading data for subject 5\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed data, labels and codes for covert and overt conditions\n",
    "\n",
    "# data\n",
    "X_overt = np.zeros((n_subjects, n_runs_ov* n_trials, n_channels, trial_time*fs)) # n_subjects x (n_runs*trials x channels x samples)\n",
    "X_covert = np.zeros((n_subjects, n_runs_cov* n_trials, n_channels, trial_time*fs)) # n_subjects x (n_runs*trials x channels x samples)\n",
    "\n",
    "# labels\n",
    "y_overt = np.zeros((n_subjects, n_runs_ov* n_trials))\n",
    "y_covert = np.zeros((n_subjects, n_runs_cov* n_trials))\n",
    "\n",
    "for i_subject, (sub_cov, sub_ov) in enumerate(zip(subjects_covert, subjects_overt)):\n",
    "    \n",
    "    print(f\"loading data for subject {i_subject+1}\")\n",
    "    sub_num = sub_cov.split('_')[0]\n",
    "    \n",
    "    # file names\n",
    "    fn_overt = os.path.join(data_path, sub_num, sub_ov)\n",
    "    fn_covert = os.path.join(data_path, sub_num, sub_cov)\n",
    "    \n",
    "    #loading overt data\n",
    "    tmp_overt = np.load(fn_overt)\n",
    "    X_overt[i_subject] = tmp_overt[\"X\"] # eeg data\n",
    "    y_overt[i_subject] = tmp_overt[\"y\"] # trial labels\n",
    "    V = tmp_overt['V'].T # codes: note, these codes will be now used throughout the notebook!\n",
    "    \n",
    "    #loading covert data\n",
    "    tmp_covert = np.load(fn_covert)\n",
    "    X_covert[i_subject] = tmp_covert[\"X\"] # eeg data\n",
    "    y_covert[i_subject] = tmp_covert[\"y\"] # trial labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished computing accuracy results for subject1\n",
      "finished computing accuracy results for subject2\n",
      "finished computing accuracy results for subject3\n",
      "finished computing accuracy results for subject4\n",
      "finished computing accuracy results for subject5\n",
      "files stored successfully\n"
     ]
    }
   ],
   "source": [
    "#1. Compare classification accuracies across modeled transient response lengths\n",
    "transient_size_vec = np.arange(0.1, 1.0, 0.1) # varying transient response lengths from 0.1s to .9s\n",
    "n_transient_sizes = len(transient_size_vec)\n",
    "\n",
    "# initializing variables for collecting accuracy\n",
    "n_folds = 4 # 4 fold cross validation\n",
    "accuracy_across_ts_covert = np.zeros((n_subjects, n_transient_sizes, n_folds)) \n",
    "accuracy_across_ts_overt = np.zeros((n_subjects, n_transient_sizes, n_folds))\n",
    "\n",
    "for i_subject in range(n_subjects):\n",
    "    \n",
    "    # overt data and labels\n",
    "    X_ov = X_overt[i_subject]\n",
    "    y_ov = y_overt[i_subject]\n",
    "    \n",
    "    # covert data and labels\n",
    "    X_cov = X_covert[i_subject]\n",
    "    y_cov = y_covert[i_subject]\n",
    "    \n",
    "    for i_ts in range(transient_size_vec.shape[0]):\n",
    "        transient_size = transient_size_vec[i_ts]\n",
    "        accuracy_across_ts_overt[i_subject, i_ts, :] = accuracy_across_folds(X = X_ov, y = y_ov, codes = V, fs = fs, trial_time= trial_time, transient_size= transient_size)        \n",
    "        accuracy_across_ts_covert[i_subject, i_ts, :] = accuracy_across_folds(X = X_cov, y = y_cov, codes = V, fs = fs, trial_time= trial_time, transient_size= transient_size)\n",
    "        \n",
    "    print(f\"finished computing accuracy results for subject{i_subject + 1}\")\n",
    "    \n",
    "# saving files\n",
    "accuracy_across_ts = {'overt_condition': accuracy_across_ts_overt, 'covert_condition': accuracy_across_ts_covert}\n",
    "fname = os.path.join(results_path, 'accuracy_across_transient_responses.pickle')\n",
    "with open(fname, 'wb') as handle:\n",
    "    pickle.dump(accuracy_across_ts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('files stored successfully')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overt condition: mean accuracy of all subjects for all transient response lengths [[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "covert condition: min and max mean accuracy observed in subjects across all transient response lengths [0.55, 0.9875]\n",
      "files saved successfully\n"
     ]
    }
   ],
   "source": [
    "#2. Finding classification accuracies at the optimum transient response length\n",
    "mean_accuracy_across_folds_overt = accuracy_across_ts_overt.mean(axis = 2) # averaging in the fold dimension\n",
    "mean_accuracy_across_folds_covert = accuracy_across_ts_covert.mean(axis = 2)    \n",
    "\n",
    "# range of accuracies\n",
    "range_acc_covert = [np.min(mean_accuracy_across_folds_covert), np.max(mean_accuracy_across_folds_covert)]\n",
    "range_acc_overt = [np.min(mean_accuracy_across_folds_overt[:]), np.max(mean_accuracy_across_folds_overt[:])]\n",
    "acc_overt_across_subjects = mean_accuracy_across_folds_overt\n",
    "\n",
    "print(f\"overt condition: mean accuracy of all subjects for all transient response lengths {acc_overt_across_subjects}\")\n",
    "print(f\"covert condition: min and max mean accuracy observed in subjects across all transient response lengths {range_acc_covert}\")\n",
    "\n",
    "# identifying the optimum transient response length and finding corresponding accuracies\n",
    "optimum_resp_len = transient_size_vec[np.argmax(mean_accuracy_across_folds_covert.mean(axis = 0))]\n",
    "mean_acc_opt_resp_len_overt = mean_accuracy_across_folds_overt[:, transient_size_vec == optimum_resp_len]\n",
    "mean_acc_opt_resp_len_covert = mean_accuracy_across_folds_covert[:, transient_size_vec == optimum_resp_len]\n",
    "\n",
    "# saving files\n",
    "mean_accuracy_optimum_resp_len ={'overt_condition': mean_acc_opt_resp_len_overt, 'covert_condition': mean_acc_opt_resp_len_covert}\n",
    "fname = os.path.join(results_path, 'mean_accuracy_at_optimum_response_length.pickle')\n",
    "with open(fname, 'wb') as handle:\n",
    "    pickle.dump(mean_accuracy_optimum_resp_len, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"files saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating results for subject 1\n",
      "calculating results for subject 2\n",
      "calculating results for subject 3\n",
      "calculating results for subject 4\n",
      "calculating results for subject 5\n",
      "files saved successfully\n"
     ]
    }
   ],
   "source": [
    "#3. computing spatial activity and transient response curves at the optimum response length\n",
    "num_events = analysis_params['NUM_EVENTS'] # number of events (short, long and onset)\n",
    "len_transient_response = int(optimum_resp_len * fs * num_events)\n",
    "\n",
    "# transient response curve\n",
    "r_overt = np.zeros((len(subjects_covert),len_transient_response)) \n",
    "r_covert = np.zeros((len(subjects_covert),len_transient_response))\n",
    "\n",
    "# activity pattern\n",
    "activity_pat_overt = np.zeros((len(subjects_covert), n_channels))\n",
    "activity_pat_covert= np.zeros((len(subjects_covert), n_channels))\n",
    "\n",
    "for i_subject in range(n_subjects):\n",
    "    \n",
    "    print(f'calculating results for subject {i_subject+1}')\n",
    "    \n",
    "    # overt data and labels\n",
    "    X_ov = X_overt[i_subject]\n",
    "    y_ov = y_overt[i_subject]\n",
    "    \n",
    "    # covert data and labels\n",
    "    X_cov = X_covert[i_subject]\n",
    "    y_cov = y_covert[i_subject]\n",
    "    \n",
    "    # computing spatial filters and transient responses: overt\n",
    "    rcca_ov = pyntbci.classifiers.rCCA(codes=V, fs=fs, event=\"duration\", transient_size=optimum_resp_len, onset_event=True)\n",
    "    rcca_ov.fit(X = X_ov, y = y_ov)\n",
    "    w_ov, r_overt[i_subject] = rcca_ov.w_.flatten(), rcca_ov.r_.flatten()\n",
    "    \n",
    "    # computing spatial filters and transient responses: covert\n",
    "    rcca_cov = pyntbci.classifiers.rCCA(codes=V, fs=fs, event=\"duration\", transient_size=optimum_resp_len, onset_event=True)\n",
    "    rcca_cov.fit(X = X_cov, y = y_cov)\n",
    "    w_cov, r_covert[i_subject] = rcca_cov.w_.flatten(), rcca_cov.r_.flatten()\n",
    "    \n",
    "    # compute covariance matrices activity pattern np.dot(w.T,np.cov(X))\n",
    "    X_ov = np.transpose(X_ov, axes = [1,0,2] )\n",
    "    X_cov = np.transpose(X_cov, axes = [1,0,2])\n",
    "\n",
    "    # covariance matrices\n",
    "    X_ov_covar = np.cov(X_ov.reshape(X_ov.shape[0],X_ov.shape[1]*X_ov.shape[2])) # channels x (trials x samples)\n",
    "    X_cov_covar = np.cov(X_cov.reshape(X_cov.shape[0],X_cov.shape[1]*X_cov.shape[2]))# channels x (trials x samples)\n",
    "\n",
    "    # compute activity pattern np.dot(w.T,np.cov(X))\n",
    "    activity_pat_overt[i_subject] = np.dot(w_ov.T,X_ov_covar)\n",
    "    activity_pat_covert[i_subject] = np.dot(w_cov.T,X_cov_covar)\n",
    "    \n",
    "\n",
    "# saving files\n",
    "spatial_activity_and_tr_responses = {'activity_pattern_overt':activity_pat_overt, 'transient_response_overt':r_overt, 'activity_pattern_covert': activity_pat_covert, 'transient_response_covert':r_covert}\n",
    "fname = os.path.join(results_path,'spatial_activity_and_transient_responses.pickle')\n",
    "with open(fname, 'wb') as handle:\n",
    "    pickle.dump(spatial_activity_and_tr_responses, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"files saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating results for subject 1\n",
      "obs, perm_test ov 1.0 [0.5375 0.3625 0.4875 0.5    0.5375 0.5    0.45   0.5125 0.5375 0.4875]\n",
      "covert p val 0.0\n",
      "overt p val 0.0\n",
      "calculating results for subject 2\n",
      "obs, perm_test ov 1.0 [0.5375 0.425  0.3875 0.4125 0.5625 0.475  0.475  0.4625 0.5625 0.5125]\n",
      "covert p val 0.0\n",
      "overt p val 0.0\n",
      "calculating results for subject 3\n",
      "obs, perm_test ov 1.0 [0.45   0.525  0.5    0.475  0.3375 0.5375 0.5    0.475  0.4125 0.5375]\n",
      "covert p val 0.0\n",
      "overt p val 0.0\n",
      "calculating results for subject 4\n",
      "obs, perm_test ov 1.0 [0.4625 0.4625 0.4625 0.4625 0.625  0.6125 0.575  0.5125 0.4875 0.4125]\n",
      "covert p val 0.0\n",
      "overt p val 0.0\n",
      "calculating results for subject 5\n",
      "obs, perm_test ov 1.0 [0.6    0.4    0.425  0.45   0.6    0.6    0.475  0.625  0.475  0.4625]\n",
      "covert p val 0.0\n",
      "overt p val 0.0\n"
     ]
    }
   ],
   "source": [
    "# 4. permutation testing (run time: approx 6 hours)\n",
    "\n",
    "# initializing parameters and constants\n",
    "transient_size = optimum_resp_len # optimum transient response duration\n",
    "num_iter = 10 # number of iterations in the permutation test\n",
    "\n",
    "# vectors to store accuracy results\n",
    "perm_test_acc_ov = np.zeros((num_iter))\n",
    "perm_test_acc_cov = np.zeros((num_iter))\n",
    "\n",
    "# important variables to save\n",
    "covert_dict_permutation_testing = {}\n",
    "overt_dict_permutation_testing = {}\n",
    "\n",
    "for i_subject in range(n_subjects):\n",
    "\n",
    "    print(f'calculating results for subject {i_subject+1}')\n",
    "    \n",
    "    # overt data and labels\n",
    "    X_ov = X_overt[i_subject]\n",
    "    y_ov = y_overt[i_subject]\n",
    "    \n",
    "    # covert data and labels\n",
    "    X_cov = X_covert[i_subject]\n",
    "    y_cov = y_covert[i_subject]\n",
    "    \n",
    "    # observed accuracy (averaged across folds)\n",
    "    observed_acc_ov = accuracy_across_folds(X = X_ov, y = y_ov, codes = V, fs = fs, trial_time= trial_time, transient_size= transient_size).mean()    \n",
    "    observed_acc_cov = accuracy_across_folds(X = X_cov, y = y_cov, codes = V, fs = fs, trial_time= trial_time, transient_size= transient_size).mean()\n",
    "       \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        perm_test_acc_ov[iter] = accuracy_across_folds(X = X_ov, y = np.random.permutation(y_ov), codes = V, fs =fs, transient_size = transient_size, trial_time= 20, n_folds=4).mean()\n",
    "        perm_test_acc_cov[iter] = accuracy_across_folds(X = X_cov, y = np.random.permutation(y_cov), codes = V, fs = fs, transient_size = transient_size, trial_time= 20, n_folds=4).mean() \n",
    "\n",
    "    # p values\n",
    "    pvalue_ov = np.mean(perm_test_acc_ov>= observed_acc_ov)\n",
    "    pvalue_cov = np.mean(perm_test_acc_cov >= observed_acc_cov)\n",
    "    \n",
    "    \n",
    "    #  collecting info        \n",
    "    overt_dict_permutation_testing[f\"S{i_subject}_rand_acc_vec\"] = perm_test_acc_ov\n",
    "    overt_dict_permutation_testing[f\"S{i_subject}_observed_acc\"] = observed_acc_ov\n",
    "    overt_dict_permutation_testing[f\"S{i_subject}_pvalue\"] = pvalue_ov\n",
    "    \n",
    "    covert_dict_permutation_testing[f\"S{i_subject}_rand_acc_vec\"] = perm_test_acc_cov\n",
    "    covert_dict_permutation_testing[f\"S{i_subject}_observed_acc\"] = observed_acc_cov\n",
    "    covert_dict_permutation_testing[f\"S{i_subject}_pvalue\"] = pvalue_cov\n",
    "\n",
    "    \n",
    "# saving files\n",
    "with open(os.path.join(results_path,\"overt_permutation_test_var.pkl\"), 'wb') as pickle_file:\n",
    "    pickle.dump(overt_dict_permutation_testing, pickle_file)\n",
    "\n",
    "with open(os.path.join(results_path,\"covert_permutation_test_var.pkl\"), 'wb') as pickle_file:\n",
    "    pickle.dump(overt_dict_permutation_testing, pickle_file)\n",
    "    \n",
    "print(\"files saved successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
