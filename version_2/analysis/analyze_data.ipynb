{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from matplotlib  import pyplot as plt\n",
    "import pyntbci\n",
    "import os\n",
    "import yaml\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining relevant functions\n",
    "def accuracy_across_folds(X: np.ndarray, y: np.ndarray, codes: np.ndarray, fs: int, transient_size:float, trial_time:int, n_folds:int=4, plot:bool = False):\n",
    "    \"\"\"\n",
    "    Computes classification accuracy for n = n_folds\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): EEG data (trials x channels x samples)\n",
    "        y (np.ndarray): labels of trials\n",
    "        codes (np.ndarray): codes used in the experiment\n",
    "        fs (int): downsampling frequency\n",
    "        transient_size (float): duration of the transient response in seconds\n",
    "        trial_time (int): duration for which codes were flashing on the screen\n",
    "        n_folds (int, optional): number of folds for cross-validation. Defaults to 4.\n",
    "        plot (bool, optional): plot the accuracy per fold. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.array: row vector containing accuracies of n_folds\n",
    "    \"\"\"\n",
    " \n",
    "    n_samples = int(trial_time * fs)\n",
    "    n_trials = X.shape[0]\n",
    "    n_classes = codes.shape[0]\n",
    "    \n",
    "    # Chronological cross-validation\n",
    "    folds = np.repeat(np.arange(n_folds), int(n_trials / n_folds))\n",
    "    \n",
    "    # Loop folds over different transient sizes\n",
    "    accuracy = np.zeros(n_folds)\n",
    "\n",
    "    for i_fold in range(n_folds):\n",
    "        \n",
    "        # Split data to train and test set\n",
    "        X_trn, y_trn = X[folds != i_fold, :, :n_samples], y[folds != i_fold]\n",
    "        X_tst, y_tst = X[folds == i_fold, :, :n_samples], y[folds == i_fold]\n",
    "\n",
    "        # Train template-matching classifier\n",
    "        rcca = pyntbci.classifiers.rCCA(codes= codes, fs = fs, event = \"duration\", transient_size = transient_size, onset_event = True)\n",
    "        rcca.fit(X_trn, y_trn)\n",
    "\n",
    "        # Apply template-matching classifier\n",
    "        yh_tst = rcca.predict(X_tst)\n",
    "\n",
    "        # Compute accuracy\n",
    "        accuracy[i_fold] = np.mean(yh_tst == y_tst)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        plt.bar(np.arange(n_folds), accuracy)\n",
    "        plt.axhline(accuracy.mean(), linestyle='--', alpha=0.5, label=\"average\")\n",
    "        plt.axhline(1 / n_classes, color=\"k\", linestyle=\"--\", alpha=0.5, label=\"chance\")\n",
    "        plt.xlabel(\"(test) fold\")\n",
    "        plt.ylabel(\"accuracy\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Chronological cross-validation\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "project_path = r'C:\\Users\\s1081686\\Desktop\\RA_Project\\Scripts\\pynt_codes\\version_2'\n",
    "\n",
    "# load relevant parameters\n",
    "with open(os.path.join(project_path,'config.yml'), \"r\") as yaml_file:\n",
    "    config_data = yaml.safe_load(yaml_file)\n",
    "    \n",
    "analysis_params = config_data['analysis_params']\n",
    "experimental_params = config_data['experimental_params']\n",
    "\n",
    "n_trials = experimental_params['N_TRIALS']\n",
    "trial_time = experimental_params['TRIAL_TIME']\n",
    "\n",
    "n_channels = 63 #analysis_params['N_CHANNELS']\n",
    "fs = analysis_params['Fs'] # downsampled frequency\n",
    "n_subjects = analysis_params['N_SUBJECTS']\n",
    "n_runs_ov = analysis_params['N_RUNS_OVERT'] # number of runs in the overt condition\n",
    "n_runs_cov = analysis_params['N_RUNS_COVERT']\n",
    "\n",
    "# loading paths\n",
    "data_path = analysis_params['DATA_PATH']\n",
    "\n",
    "# preprocessed eeg data filenames of all subjects\n",
    "subjects_overt = analysis_params['subjects_overt']\n",
    "subjects_covert = analysis_params['subjects_covert']\n",
    "\n",
    "# path to store results\n",
    "results_path = os.path.join(project_path,'analysis_version2','result_variables')\n",
    "\n",
    "print(n_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data for subject 1\n",
      "loading data for subject 2\n",
      "loading data for subject 3\n",
      "loading data for subject 4\n",
      "loading data for subject 5\n",
      "loading data for subject 6\n",
      "Loading data finished\n",
      "shape of overt data for a praticipant (20, 63, 2400), shape of labels (20,)\n",
      "shape of covert data for a praticipant (80, 63, 2400), shape of labels (80,)\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed data, labels and codes for covert and overt conditions\n",
    "\n",
    "# data\n",
    "X_overt = np.zeros((n_subjects, n_runs_ov* n_trials, n_channels, trial_time*fs)) # n_subjects x (n_runs*trials x channels x samples)\n",
    "X_covert = np.zeros((n_subjects, n_runs_cov* n_trials, n_channels, trial_time*fs)) # n_subjects x (n_runs*trials x channels x samples)\n",
    "\n",
    "# labels\n",
    "y_overt = np.zeros((n_subjects, n_runs_ov* n_trials))\n",
    "y_covert = np.zeros((n_subjects, n_runs_cov* n_trials))\n",
    "\n",
    "for i_subject, (sub_cov, sub_ov) in enumerate(zip(subjects_covert, subjects_overt)):\n",
    "    \n",
    "    print(f\"loading data for subject {i_subject+1}\")\n",
    "    sub_num = sub_cov.split('_')[0]\n",
    "    \n",
    "    # file names\n",
    "    fn_overt = os.path.join(data_path, sub_num, sub_ov)\n",
    "    fn_covert = os.path.join(data_path, sub_num, sub_cov)\n",
    "    \n",
    "    \n",
    "    #loading overt data\n",
    "    tmp_overt = np.load(fn_overt)\n",
    "    X_overt[i_subject] = tmp_overt[\"X\"] # eeg data\n",
    "    y_overt[i_subject] = tmp_overt[\"y\"] # trial labels\n",
    "    V = tmp_overt['V'] # codes: note, these codes will be now used throughout the notebook!\n",
    "    \n",
    "    #loading covert data\n",
    "    tmp_covert = np.load(fn_covert)\n",
    "    X_covert[i_subject] = tmp_covert[\"X\"] # eeg data\n",
    "    y_covert[i_subject] = tmp_covert[\"y\"] # trial labels\n",
    "    \n",
    "print(\"Loading data finished\")\n",
    "print(f\"shape of overt data for a praticipant {X_overt[i_subject].shape}, shape of labels {y_overt[i_subject].shape}\")\n",
    "print(f\"shape of covert data for a praticipant {X_covert[i_subject].shape}, shape of labels {y_covert[i_subject].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overt data shape (6, 20, 63, 2400)\n",
      "covert data shape (6, 80, 63, 2400)\n",
      "codes shape (2, 252)\n"
     ]
    }
   ],
   "source": [
    "print(\"overt data shape\", X_overt.shape)\n",
    "print(\"covert data shape\", X_covert.shape)\n",
    "print(\"codes shape\", V.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished computing accuracy results for subject1\n",
      "finished computing accuracy results for subject2\n",
      "finished computing accuracy results for subject3\n",
      "finished computing accuracy results for subject4\n",
      "finished computing accuracy results for subject5\n",
      "finished computing accuracy results for subject6\n",
      "files stored successfully\n"
     ]
    }
   ],
   "source": [
    "#1. Compare classification accuracies across modeled transient response lengths\n",
    "transient_size_vec = np.arange(0.1, 1, 0.1) # varying transient response lengths from 0.1s to .9s\n",
    "n_transient_sizes = len(transient_size_vec)\n",
    "\n",
    "# initializing variables for collecting accuracy\n",
    "n_folds = 4 # 4 fold cross validation\n",
    "accuracy_across_ts_covert = np.zeros((n_subjects, n_transient_sizes, n_folds)) \n",
    "accuracy_across_ts_overt = np.zeros((n_subjects, n_transient_sizes, n_folds))\n",
    "\n",
    "for i_subject in range(n_subjects):\n",
    "    \n",
    "    # overt data and labels\n",
    "    X_ov = X_overt[i_subject]\n",
    "    y_ov = y_overt[i_subject]\n",
    "    \n",
    "    # covert data and labels\n",
    "    X_cov = X_covert[i_subject]\n",
    "    y_cov = y_covert[i_subject]\n",
    "    \n",
    "    for i_ts in range(transient_size_vec.shape[0]):\n",
    "        transient_size = transient_size_vec[i_ts]\n",
    "        accuracy_across_ts_overt[i_subject, i_ts, :] = accuracy_across_folds(X = X_ov, y = y_ov, codes = V, fs = fs, trial_time= trial_time, transient_size= transient_size)        \n",
    "        accuracy_across_ts_covert[i_subject, i_ts, :] = accuracy_across_folds(X = X_cov, y = y_cov, codes = V, fs = fs, trial_time= trial_time, transient_size= transient_size)\n",
    "        \n",
    "    print(f\"finished computing accuracy results for subject{i_subject + 1}\")\n",
    "    \n",
    "# # saving files\n",
    "accuracy_across_ts = {'overt_condition': accuracy_across_ts_overt, 'covert_condition': accuracy_across_ts_covert}\n",
    "fname = os.path.join(results_path, 'accuracy_across_transient_responses.pickle')\n",
    "with open(fname, 'wb') as handle:\n",
    "    pickle.dump(accuracy_across_ts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('files stored successfully')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overt condition: mean accuracy of all subjects for all transient response lengths [[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "covert condition: min and max mean accuracy observed in subjects across all transient response lengths [0.4625, 0.725]\n",
      "files saved successfully\n"
     ]
    }
   ],
   "source": [
    "#2. Finding classification accuracies at the optimum transient response length\n",
    "mean_accuracy_across_folds_overt = accuracy_across_ts_overt.mean(axis = 2) # averaging in the fold dimension\n",
    "mean_accuracy_across_folds_covert = accuracy_across_ts_covert.mean(axis = 2)    \n",
    "\n",
    "# range of accuracies\n",
    "range_acc_covert = [np.min(mean_accuracy_across_folds_covert), np.max(mean_accuracy_across_folds_covert)]\n",
    "range_acc_overt = [np.min(mean_accuracy_across_folds_overt[:]), np.max(mean_accuracy_across_folds_overt[:])]\n",
    "acc_overt_across_subjects = mean_accuracy_across_folds_overt\n",
    "\n",
    "print(f\"overt condition: mean accuracy of all subjects for all transient response lengths {acc_overt_across_subjects}\")\n",
    "print(f\"covert condition: min and max mean accuracy observed in subjects across all transient response lengths {range_acc_covert}\")\n",
    "\n",
    "# identifying the optimum transient response length and finding corresponding accuracies\n",
    "optimum_resp_len = transient_size_vec[np.argmax(mean_accuracy_across_folds_covert.mean(axis = 0))]\n",
    "mean_acc_opt_resp_len_overt = mean_accuracy_across_folds_overt[:, transient_size_vec == optimum_resp_len]\n",
    "mean_acc_opt_resp_len_covert = mean_accuracy_across_folds_covert[:, transient_size_vec == optimum_resp_len]\n",
    "\n",
    "# # saving files\n",
    "mean_accuracy_optimum_resp_len ={'overt_condition': mean_acc_opt_resp_len_overt, 'covert_condition': mean_acc_opt_resp_len_covert}\n",
    "fname = os.path.join(results_path, 'mean_accuracy_at_optimum_response_length.pickle')\n",
    "with open(fname, 'wb') as handle:\n",
    "    pickle.dump(mean_accuracy_optimum_resp_len, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"files saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating results for subject 1\n",
      "(6, 216)\n",
      "files saved successfully\n",
      "calculating results for subject 2\n",
      "(6, 216)\n",
      "files saved successfully\n",
      "calculating results for subject 3\n",
      "(6, 216)\n",
      "files saved successfully\n",
      "calculating results for subject 4\n",
      "(6, 216)\n",
      "files saved successfully\n",
      "calculating results for subject 5\n",
      "(6, 216)\n",
      "files saved successfully\n",
      "calculating results for subject 6\n",
      "(6, 216)\n",
      "files saved successfully\n"
     ]
    }
   ],
   "source": [
    "#3. computing spatial activity and transient response curves at the optimum response length\n",
    "num_events = analysis_params['NUM_EVENTS'] # number of events (short, long and onset)\n",
    "len_transient_response = int(optimum_resp_len * fs * num_events)\n",
    "\n",
    "# transient response curve\n",
    "r_overt = np.zeros((len(subjects_covert),len_transient_response)) \n",
    "r_covert = np.zeros((len(subjects_covert),len_transient_response))\n",
    "\n",
    "# activity pattern\n",
    "activity_pat_overt = np.zeros((len(subjects_covert), n_channels))\n",
    "activity_pat_covert= np.zeros((len(subjects_covert), n_channels))\n",
    "\n",
    "for i_subject in range(n_subjects):\n",
    "    \n",
    "    print(f'calculating results for subject {i_subject+1}')\n",
    "    \n",
    "    # overt data and labels\n",
    "    X_ov = X_overt[i_subject]\n",
    "    y_ov = y_overt[i_subject]\n",
    "    \n",
    "    # covert data and labels\n",
    "    X_cov = X_covert[i_subject]\n",
    "    y_cov = y_covert[i_subject]\n",
    "    \n",
    "    # computing spatial filters and transient responses: overt\n",
    "    rcca_ov = pyntbci.classifiers.rCCA(codes=V, fs=fs, event=\"duration\", transient_size=optimum_resp_len, onset_event=True)\n",
    "    rcca_ov.fit(X = X_ov, y = y_ov)\n",
    "    w_ov, r_overt[i_subject] = rcca_ov.w_.flatten(), rcca_ov.r_.flatten()\n",
    "    \n",
    "    # computing spatial filters and transient responses: covert\n",
    "    rcca_cov = pyntbci.classifiers.rCCA(codes=V, fs=fs, event=\"duration\", transient_size=optimum_resp_len, onset_event=True)\n",
    "    rcca_cov.fit(X = X_cov, y = y_cov)\n",
    "    w_cov, r_covert[i_subject] = rcca_cov.w_.flatten(), rcca_cov.r_.flatten()\n",
    "    \n",
    "    # compute covariance matrices activity pattern np.dot(w.T,np.cov(X))\n",
    "    X_ov = np.transpose(X_ov, axes = [1,0,2] )\n",
    "    X_cov = np.transpose(X_cov, axes = [1,0,2])\n",
    "\n",
    "    # covariance matrices\n",
    "    X_ov_covar = np.cov(X_ov.reshape(X_ov.shape[0],X_ov.shape[1]*X_ov.shape[2])) # channels x (trials x samples)\n",
    "    X_cov_covar = np.cov(X_cov.reshape(X_cov.shape[0],X_cov.shape[1]*X_cov.shape[2]))# channels x (trials x samples)\n",
    "\n",
    "    # compute activity pattern np.dot(w.T,np.cov(X))\n",
    "    activity_pat_overt[i_subject] = np.dot(w_ov.T,X_ov_covar)\n",
    "    activity_pat_covert[i_subject] = np.dot(w_cov.T,X_cov_covar)\n",
    "    \n",
    "    print(r_overt.shape)\n",
    "\n",
    "    # # saving files\n",
    "    spatial_activity_and_tr_responses = {'activity_pattern_overt':activity_pat_overt, \n",
    "                                         'transient_response_overt':r_overt, \n",
    "                                         'activity_pattern_covert': activity_pat_covert, \n",
    "                                         'transient_response_covert':r_covert,\n",
    "                                         'transient_size':optimum_resp_len}\n",
    "    \n",
    "    fname = os.path.join(results_path,f'spatial_activity_and_transient_responses_S{i_subject}.pickle')\n",
    "    with open(fname, 'wb') as handle:\n",
    "        pickle.dump(spatial_activity_and_tr_responses, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"files saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating results for subject 1\n",
      "calculating results for subject 2\n",
      "calculating results for subject 3\n",
      "calculating results for subject 4\n",
      "calculating results for subject 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iter):\n\u001b[0;32m     33\u001b[0m     perm_test_acc_ov[\u001b[38;5;28miter\u001b[39m] \u001b[38;5;241m=\u001b[39m accuracy_across_folds(X \u001b[38;5;241m=\u001b[39m X_ov, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(y_ov), codes \u001b[38;5;241m=\u001b[39m V, fs \u001b[38;5;241m=\u001b[39mfs, transient_size \u001b[38;5;241m=\u001b[39m transient_size, trial_time\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, n_folds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m---> 34\u001b[0m     perm_test_acc_cov[\u001b[38;5;28miter\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_across_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_cov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermutation\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_cov\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransient_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransient_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean() \n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# p values\u001b[39;00m\n\u001b[0;32m     37\u001b[0m pvalue_ov \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(perm_test_acc_ov\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m observed_acc_ov)\n",
      "Cell \u001b[1;32mIn[32], line 38\u001b[0m, in \u001b[0;36maccuracy_across_folds\u001b[1;34m(X, y, codes, fs, transient_size, trial_time, n_folds, plot)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Train template-matching classifier\u001b[39;00m\n\u001b[0;32m     37\u001b[0m rcca \u001b[38;5;241m=\u001b[39m pyntbci\u001b[38;5;241m.\u001b[39mclassifiers\u001b[38;5;241m.\u001b[39mrCCA(codes\u001b[38;5;241m=\u001b[39m codes, fs \u001b[38;5;241m=\u001b[39m fs, event \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m\"\u001b[39m, transient_size \u001b[38;5;241m=\u001b[39m transient_size, onset_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 38\u001b[0m \u001b[43mrcca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Apply template-matching classifier\u001b[39;00m\n\u001b[0;32m     41\u001b[0m yh_tst \u001b[38;5;241m=\u001b[39m rcca\u001b[38;5;241m.\u001b[39mpredict(X_tst)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyntbci\\classifiers.py:779\u001b[0m, in \u001b[0;36mrCCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cca \u001b[38;5;241m=\u001b[39m CCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, lx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlx, ly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mly)\n\u001b[0;32m    778\u001b[0m \u001b[38;5;66;03m# if you get a 'cant accept inf or nan error, the shape of V (codes) is incorrect! it should be n_classes x n_samples\u001b[39;00m\n\u001b[1;32m--> 779\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cca\u001b[38;5;241m.\u001b[39mw_x_\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cca\u001b[38;5;241m.\u001b[39mw_y_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyntbci\\transformers.py:224\u001b[0m, in \u001b[0;36mCCA.fit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_x_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_y_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_x_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_y_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_x_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_y_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X3D_Y1D(X, Y)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_x_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_y_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_x_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_y_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_x_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_y_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X3D_Y3D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_x_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_y_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_x_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_y_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_x_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_y_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X2D_Y2D(X, Y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyntbci\\transformers.py:157\u001b[0m, in \u001b[0;36mCCA._fit_X3D_Y3D\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    154\u001b[0m Y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape((n_samples \u001b[38;5;241m*\u001b[39m n_trials, n_features_y))\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# CCA\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m w_x, w_y, mu_x, mu_y, sigma_x, sigma_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X2D_Y2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m w_x, w_y, mu_x, mu_y, sigma_x, sigma_y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyntbci\\transformers.py:81\u001b[0m, in \u001b[0;36mCCA._fit_X2D_Y2D\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Regularization penalty\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     lx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlx, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlx, \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m     83\u001b[0m     lx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlx \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 4. permutation testing (run time: approx 6 hours)\n",
    "\n",
    "# initializing parameters and constants\n",
    "transient_size = optimum_resp_len # optimum transient response duration\n",
    "num_iter = 10 # number of iterations in the permutation test\n",
    "\n",
    "# vectors to store accuracy results\n",
    "perm_test_acc_ov = np.zeros((num_iter))\n",
    "perm_test_acc_cov = np.zeros((num_iter))\n",
    "\n",
    "# important variables to save\n",
    "covert_dict_permutation_testing = {}\n",
    "overt_dict_permutation_testing = {}\n",
    "\n",
    "for i_subject in range(n_subjects):\n",
    "\n",
    "    print(f'calculating results for subject {i_subject+1}')\n",
    "    \n",
    "    # overt data and labels\n",
    "    X_ov = X_overt[i_subject]\n",
    "    y_ov = y_overt[i_subject]\n",
    "    \n",
    "    # covert data and labels\n",
    "    X_cov = X_covert[i_subject]\n",
    "    y_cov = y_covert[i_subject]\n",
    "    \n",
    "    # observed accuracy (averaged across folds)\n",
    "    observed_acc_ov = accuracy_across_folds(X = X_ov, y = y_ov, codes = V, fs = fs, trial_time= trial_time, transient_size= transient_size).mean()    \n",
    "    observed_acc_cov = accuracy_across_folds(X = X_cov, y = y_cov, codes = V, fs = fs, trial_time= trial_time, transient_size= transient_size).mean()\n",
    "       \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        perm_test_acc_ov[iter] = accuracy_across_folds(X = X_ov, y = np.random.permutation(y_ov), codes = V, fs =fs, transient_size = transient_size, trial_time= 20, n_folds=4).mean()\n",
    "        perm_test_acc_cov[iter] = accuracy_across_folds(X = X_cov, y = np.random.permutation(y_cov), codes = V, fs = fs, transient_size = transient_size, trial_time= 20, n_folds=4).mean() \n",
    "\n",
    "    # p values\n",
    "    pvalue_ov = np.mean(perm_test_acc_ov>= observed_acc_ov)\n",
    "    pvalue_cov = np.mean(perm_test_acc_cov >= observed_acc_cov)\n",
    "    \n",
    "    \n",
    "    #  collecting info        \n",
    "    overt_dict_permutation_testing[f\"S{i_subject}_rand_acc_vec\"] = perm_test_acc_ov\n",
    "    overt_dict_permutation_testing[f\"S{i_subject}_observed_acc\"] = observed_acc_ov\n",
    "    overt_dict_permutation_testing[f\"S{i_subject}_pvalue\"] = pvalue_ov\n",
    "    \n",
    "    covert_dict_permutation_testing[f\"S{i_subject}_rand_acc_vec\"] = perm_test_acc_cov\n",
    "    covert_dict_permutation_testing[f\"S{i_subject}_observed_acc\"] = observed_acc_cov\n",
    "    covert_dict_permutation_testing[f\"S{i_subject}_pvalue\"] = pvalue_cov\n",
    "\n",
    "    \n",
    "# saving files\n",
    "with open(os.path.join(results_path,\"overt_permutation_test_var.pkl\"), 'wb') as pickle_file:\n",
    "    pickle.dump(overt_dict_permutation_testing, pickle_file)\n",
    "\n",
    "with open(os.path.join(results_path,\"covert_permutation_test_var.pkl\"), 'wb') as pickle_file:\n",
    "    pickle.dump(overt_dict_permutation_testing, pickle_file)\n",
    "    \n",
    "print(\"files saved successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
